{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WGAN-GP_Board.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "42aeaf6a24a94e48af81342f2ab79244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3d9f93edc0fb41e7947aa9a4a18d426a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a53da28d3412470dae10aaeb3ad422c2",
              "IPY_MODEL_1fe7d547180e4146ba42782a9b68cfd1"
            ]
          }
        },
        "3d9f93edc0fb41e7947aa9a4a18d426a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a53da28d3412470dae10aaeb3ad422c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6a0c8568f99446bbaef45c20a538c012",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 16,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 16,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d5a977f10244d76b9b2043573fa741d"
          }
        },
        "1fe7d547180e4146ba42782a9b68cfd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_54478e910cca43eea726a69068e43fd3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16/16 [00:14&lt;00:00,  1.11it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0bb8dc8a5d294d7fb05e53129aa7a154"
          }
        },
        "6a0c8568f99446bbaef45c20a538c012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d5a977f10244d76b9b2043573fa741d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "54478e910cca43eea726a69068e43fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0bb8dc8a5d294d7fb05e53129aa7a154": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1377b4e3bad9423794e0957b80e0ef61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6ebcc5c249d349b2a682ea9877373c2a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ce6b376b1ad44d23a5325ac8ba4ea049",
              "IPY_MODEL_1d3bac18c9e942a894afd06e4509513c"
            ]
          }
        },
        "6ebcc5c249d349b2a682ea9877373c2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce6b376b1ad44d23a5325ac8ba4ea049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ff4e6f0a9d664049b2717adf5a23c556",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 16,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 16,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0eca3e0477484ff588051c685dc82daa"
          }
        },
        "1d3bac18c9e942a894afd06e4509513c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_81a4a8ae15e348a681287992e555bb5c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16/16 [00:17&lt;00:00,  1.12s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_76ac023b1ec64c5b9c118260c344e39a"
          }
        },
        "ff4e6f0a9d664049b2717adf5a23c556": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0eca3e0477484ff588051c685dc82daa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81a4a8ae15e348a681287992e555bb5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "76ac023b1ec64c5b9c118260c344e39a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4tVdkJMn9JP"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNQ39NwKUACU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bae49dd-7783-4c1e-8314-053e0232a7fb"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.metrics import Mean\n",
        "from google.colab import drive\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm.autonotebook import tqdm\n",
        "from IPython.display import Image\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "import shutil\n",
        "from functools import partial"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKZ-COZOq3r2",
        "outputId": "f05fa43d-3888-4d2f-85aa-20112c536bf1"
      },
      "source": [
        "%cd /content/\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQfWIlF6r0aD",
        "outputId": "4a8e7027-00c2-46b2-cd3b-d6917d71d8f6"
      },
      "source": [
        "!git clone https://github.com/yxczt/project_laboratory_elozs.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'project_laboratory_elozs'...\n",
            "remote: Enumerating objects: 3651, done.\u001b[K\n",
            "remote: Counting objects: 100% (3651/3651), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3647/3647), done.\u001b[K\n",
            "remote: Total 3651 (delta 2), reused 3642 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3651/3651), 23.16 MiB | 22.65 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijHAQrTquBOi",
        "outputId": "a6f72e35-95c8-4e2f-d72d-fb9462b6d445"
      },
      "source": [
        "%cd /content/project_laboratory_elozs/\n",
        "!ls -a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/project_laboratory_elozs\n",
            ".  ..  data  .git  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5QF4DjAclBN"
      },
      "source": [
        "def pbar(total_images, batch_size, epoch, epochs):\n",
        "    bar = tqdm(total=(total_images // batch_size) * batch_size,\n",
        "               ncols=int(get_terminal_width() * .9),\n",
        "               desc=tqdm.write(f'Epoch {epoch + 1}/{epochs}'),\n",
        "               postfix={\n",
        "                   'g_loss': f'{0:6.3f}',\n",
        "                   'd_loss': f'{0:6.3f}',\n",
        "                   1: 1\n",
        "               },\n",
        "               bar_format='{n_fmt}/{total_fmt} |{bar}| {rate_fmt}  '\n",
        "               'ETA: {remaining}  Elapsed Time: {elapsed}  '\n",
        "               'G Loss: {postfix[g_loss]}  D Loss: {postfix['\n",
        "               'd_loss]}',\n",
        "               unit=' images',\n",
        "               miniters=10)\n",
        "    return bar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faVH8Nl8cnJr"
      },
      "source": [
        "def save_image_grid(img_grid, epoch):\n",
        "    file_name = 'Boards' + f'_{epoch}.png'\n",
        "    output_dir = os.path.join(\"/content/drive/MyDrive/onlab_results/training/\", file_name)\n",
        "    tf.io.write_file(output_dir, tf.image.encode_png(tf.cast(img_grid, tf.uint8)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIIpvXFCeRbs"
      },
      "source": [
        "def img_merge(images, n_rows=None, n_cols=None, padding=0, pad_value=0):\n",
        "    images = (tf.cast(images, tf.float32) + 1.0) * 127.5\n",
        "    images = np.array(images)\n",
        "    n = images.shape[0]\n",
        "\n",
        "    if n_rows:\n",
        "        n_rows = max(min(n_rows, n), 1)\n",
        "        n_cols = int(n - 0.5) // n_rows + 1\n",
        "    elif n_cols:\n",
        "        n_cols = max(min(n_cols, n), 1)\n",
        "        n_rows = int(n - 0.5) // n_cols + 1\n",
        "    else:\n",
        "        n_rows = int(n**0.5)\n",
        "        n_cols = int(n - 0.5) // n_rows + 1\n",
        "\n",
        "    h, w = images.shape[1], images.shape[2]\n",
        "    shape = (h * n_rows + padding * (n_rows - 1), w * n_cols + padding * (n_cols - 1))\n",
        "    if images.ndim == 4:\n",
        "        shape += (images.shape[3], )\n",
        "    img = np.full(shape, pad_value, dtype=images.dtype)\n",
        "\n",
        "    for idx, image in enumerate(images):\n",
        "        i = idx % n_cols\n",
        "        j = idx // n_cols\n",
        "        img[j * (h + padding):j * (h + padding) + h, i * (w + padding):i *\n",
        "            (w + padding) + w, ...] = image\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqQRcZMQbJua"
      },
      "source": [
        "def get_terminal_width():\n",
        "    width = shutil.get_terminal_size(fallback=(200, 24))[0]\n",
        "    if width == 0:\n",
        "        width = 120\n",
        "    return width"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8s9W0w2mvX6"
      },
      "source": [
        "def upsample_block(\n",
        "    x,\n",
        "    filters,\n",
        "    activation,\n",
        "    kernel_size=(3, 3),\n",
        "    strides=(1, 1),\n",
        "    up_size=(2, 2),\n",
        "    padding=\"same\",\n",
        "    use_bn=False,\n",
        "    use_bias=True,\n",
        "    use_dropout=False,\n",
        "    drop_value=0.3,\n",
        "  ):\n",
        "    x = layers.UpSampling2D(up_size)(x)\n",
        "    x = layers.Conv2D(\n",
        "        filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias\n",
        "    )(x)\n",
        "\n",
        "    if use_bn:\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "    if activation:\n",
        "        x = activation(x)\n",
        "    if use_dropout:\n",
        "        x = layers.Dropout(drop_value)(x)\n",
        "    return x\n",
        "    \n",
        "def conv_block(\n",
        "  x,\n",
        "  filters,\n",
        "  activation,\n",
        "  kernel_size=(3, 3),\n",
        "  strides=(1, 1),\n",
        "  padding=\"same\",\n",
        "  use_bias=True,\n",
        "  use_bn=False,\n",
        "  use_dropout=False,\n",
        "  drop_value=0.5,\n",
        "):\n",
        "  x = layers.Conv2D(\n",
        "      filters, kernel_size, strides=strides, padding=padding, use_bias=use_bias\n",
        "  )(x)\n",
        "  if use_bn:\n",
        "      x = layers.BatchNormalization()(x)\n",
        "  x = activation(x)\n",
        "  if use_dropout:\n",
        "      x = layers.Dropout(drop_value)(x)\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofUW2ohAWiUJ"
      },
      "source": [
        "IMG_SHAPE = (128, 128, 3)\n",
        "total_img_count = 1416\n",
        "img_size = 128\n",
        "epochs = 300\n",
        "batch = 32\n",
        "noise_dim = 1536"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72z88DXAr87s"
      },
      "source": [
        "## Defining the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwAFPcl-uu6N"
      },
      "source": [
        "class WGANGP:\n",
        "  def __init__(self, num_of_images = 1416, image_size = 128, epochs = 300, batch_size = 32, z_size = 1536, n_critic = 5, gp_weight = 10.0, loading = False):\n",
        "    self.num_of_images = num_of_images\n",
        "    self.image_size = image_size\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.z_size = z_size\n",
        "    self.n_critic = n_critic\n",
        "    self.gp_weight = gp_weight\n",
        "    if loading:\n",
        "      %cd /content/drive/MyDrive/onlab_results/first_try/\n",
        "      self.Gen = tf.keras.models.load_model(\"generator.h5\")\n",
        "      self.Disc = tf.keras.models.load_model(\"discriminator.h5\")\n",
        "    else:\n",
        "      self.Gen = self.build_generator()\n",
        "      self.Disc = self.build_discriminator()\n",
        "    self.gen_optimizer = Adam(0.0001)\n",
        "    self.disc_optimizer = Adam(0.0001)\n",
        "\n",
        "    self.Gen.summary()\n",
        "    self.Disc.summary()\n",
        "\n",
        "  def build_generator(self):\n",
        "    noise = layers.Input(shape=(1, 1, noise_dim,))\n",
        "    x = layers.Dense(4 * 4 * 96, use_bias=False)(noise)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.LeakyReLU(0.2)(x)\n",
        "\n",
        "    x = layers.Reshape((4, 4, 96))(x)\n",
        "    x = upsample_block(\n",
        "        x,\n",
        "        48,\n",
        "        layers.LeakyReLU(0.2),\n",
        "        strides=(1, 1),\n",
        "        use_bias=False,\n",
        "        use_bn=True,\n",
        "        padding=\"same\",\n",
        "        use_dropout=False,\n",
        "    )\n",
        "    x = upsample_block(\n",
        "        x,\n",
        "        24,\n",
        "        layers.LeakyReLU(0.2),\n",
        "        strides=(1, 1),\n",
        "        use_bias=False,\n",
        "        use_bn=True,\n",
        "        padding=\"same\",\n",
        "        use_dropout=False,\n",
        "    )\n",
        "    x = upsample_block(\n",
        "        x,\n",
        "        12,\n",
        "        layers.LeakyReLU(0.2),\n",
        "        strides=(1, 1),\n",
        "        use_bias=False,\n",
        "        use_bn=True,\n",
        "        padding=\"same\",\n",
        "        use_dropout=False,\n",
        "    )\n",
        "    x = upsample_block(\n",
        "        x,\n",
        "        6,\n",
        "        layers.LeakyReLU(0.2),\n",
        "        strides=(1, 1),\n",
        "        use_bias=False,\n",
        "        use_bn=True,\n",
        "        padding=\"same\",\n",
        "        use_dropout=False,\n",
        "    )\n",
        "    x = upsample_block(\n",
        "        x, 3, layers.Activation(\"tanh\"), strides=(1, 1), use_bias=False, use_bn=True\n",
        "    )\n",
        "\n",
        "    g_model = Model(noise, x, name=\"generator\")\n",
        "    return g_model\n",
        "\n",
        "\n",
        "  def build_discriminator(self):\n",
        "    img_input = layers.Input(shape=IMG_SHAPE)\n",
        "    x = conv_block(\n",
        "        img_input,\n",
        "        48,\n",
        "        kernel_size=(5, 5),\n",
        "        strides=(2, 2),\n",
        "        use_bn=False,\n",
        "        use_bias=True,\n",
        "        activation=layers.LeakyReLU(0.2),\n",
        "        use_dropout=False,\n",
        "        drop_value=0.3,\n",
        "    )\n",
        "    x = conv_block(\n",
        "        x,\n",
        "        96,\n",
        "        kernel_size=(5, 5),\n",
        "        strides=(2, 2),\n",
        "        use_bn=False,\n",
        "        activation=layers.LeakyReLU(0.2),\n",
        "        use_bias=True,\n",
        "        use_dropout=True,\n",
        "        drop_value=0.3,\n",
        "    )\n",
        "    x = conv_block(\n",
        "        x,\n",
        "        192,\n",
        "        kernel_size=(5, 5),\n",
        "        strides=(2, 2),\n",
        "        use_bn=False,\n",
        "        activation=layers.LeakyReLU(0.2),\n",
        "        use_bias=True,\n",
        "        use_dropout=True,\n",
        "        drop_value=0.3,\n",
        "    )\n",
        "    x = conv_block(\n",
        "        x,\n",
        "        384,\n",
        "        kernel_size=(5, 5),\n",
        "        strides=(2, 2),\n",
        "        use_bn=False,\n",
        "        activation=layers.LeakyReLU(0.2),\n",
        "        use_bias=True,\n",
        "        use_dropout=False,\n",
        "        drop_value=0.3,\n",
        "    )\n",
        "\n",
        "    x = layers.Flatten()(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.Dense(1)(x)\n",
        "\n",
        "    d_model = Model(img_input, x, name=\"discriminator\")\n",
        "    return d_model\n",
        "\n",
        "  def train(self, dataset):\n",
        "    z = tf.constant(tf.random.normal((self.batch_size, 1, 1, self.z_size)))\n",
        "    g_train_loss = Mean()\n",
        "    d_train_loss = Mean()\n",
        "    for epoch in range(self.epochs):\n",
        "      bar = pbar(self.num_of_images, 32, epoch, self.epochs)\n",
        "      for batch in dataset:\n",
        "        for _ in range(self.n_critic):\n",
        "          self.train_discrminator(batch)\n",
        "          d_loss = self.train_discrminator(batch)\n",
        "          d_train_loss(d_loss)\n",
        "\n",
        "        g_loss = self.train_generator()\n",
        "        g_train_loss(g_loss)\n",
        "        self.train_generator()\n",
        "\n",
        "        bar.postfix['g_loss'] = f'{g_train_loss.result():6.3f}'\n",
        "        bar.postfix['d_loss'] = f'{d_train_loss.result():6.3f}'\n",
        "        bar.update(self.batch_size)\n",
        "\n",
        "      g_train_loss.reset_states()\n",
        "      d_train_loss.reset_states()\n",
        "\n",
        "      bar.close()\n",
        "      del bar\n",
        "\n",
        "      samples = self.Gen(z, training=False)\n",
        "      image_grid = img_merge(samples, n_rows=8).squeeze()\n",
        "      save_image_grid(image_grid, epoch + 1)\n",
        "  \n",
        "  @tf.function\n",
        "  def train_generator(self):\n",
        "    z = tf.random.normal((self.batch_size, 1, 1, self.z_size))\n",
        "    with tf.GradientTape() as t:\n",
        "      x_fake = self.Gen(z, training=True)\n",
        "      fake_logits = self.Disc(x_fake, training=True)\n",
        "      loss = -(tf.reduce_mean(fake_logits))\n",
        "    grad = t.gradient(loss, self.Gen.trainable_variables)\n",
        "    self.gen_optimizer.apply_gradients(zip(grad, self.Gen.trainable_variables))\n",
        "    return loss\n",
        "  \n",
        "  @tf.function\n",
        "  def train_discrminator(self, x_real):\n",
        "    z = tf.random.normal((self.batch_size, 1, 1, self.z_size))\n",
        "    with tf.GradientTape() as t:\n",
        "      x_fake = self.Gen(z, training=True)\n",
        "      fake_logits = self.Disc(x_fake, training=True)\n",
        "      real_logits = self.Disc(x_real, training=True)\n",
        "      cost = tf.reduce_mean(fake_logits) - tf.reduce_mean(real_logits)\n",
        "      gp = self.gradient_penalty(partial(self.Disc, training=True), x_real, x_fake)\n",
        "      cost += self.gp_weight * gp\n",
        "    grad = t.gradient(cost, self.Disc.trainable_variables)\n",
        "    self.gen_optimizer.apply_gradients(zip(grad, self.Disc.trainable_variables))\n",
        "    return cost\n",
        "\n",
        "  def gradient_penalty(self, f, real, fake):\n",
        "    alpha = tf.random.uniform([self.batch_size, 1, 1, 1], 0., 1.)\n",
        "    diff = fake - real\n",
        "    inter = real + (alpha * diff)\n",
        "    with tf.GradientTape() as t:\n",
        "        t.watch(inter)\n",
        "        pred = f(inter)\n",
        "    grad = t.gradient(pred, [inter])[0]\n",
        "    slopes = tf.sqrt(tf.reduce_sum(tf.square(grad), axis=[1, 2, 3]))\n",
        "    gp = tf.reduce_mean((slopes - 1.)**2)\n",
        "    return gp\n",
        "  \n",
        "  def generate_samples(self):\n",
        "    z = tf.random.normal((self.batch_size, 1, 1, self.z_size))\n",
        "    samples = self.Gen(z, training=False)\n",
        "    image_grid = img_merge(samples, n_rows=8).squeeze()\n",
        "    file_name = 'BoardsGeneratedRandom.png'\n",
        "    output_dir = os.path.join(\"/content/drive/MyDrive/onlab_results/generated_images/\", file_name)\n",
        "    tf.io.write_file(output_dir, tf.image.encode_png(tf.cast(image_grid, tf.uint8)))\n",
        "  def saving_models(self):\n",
        "    self.Gen.save('generator.h5')\n",
        "    self.Disc.save('discriminator.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX60DRbyD_bO"
      },
      "source": [
        "# Dataset preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UDjg1aWEFF-"
      },
      "source": [
        "def decode_img(file_path):\n",
        "    file = tf.io.read_file(file_path)\n",
        "    img = tf.image.decode_png(file, channels=3)\n",
        "    img = (tf.dtypes.cast(img, tf.float32) / 127.5) - 1.0\n",
        "    return img  \n",
        "\n",
        "img_path = \"/content/project_laboratory_elozs/data/boards/\"\n",
        "ds_train_paths = tf.data.Dataset.list_files(str(img_path + '*.png'))\n",
        "\n",
        "ds_train = ds_train_paths.map(decode_img).cache().shuffle(1416).batch(32, drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-9N7nvYVF0l"
      },
      "source": [
        "unknown_image_batch = next(iter(ds_train))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "eR2do2ApVPWM",
        "outputId": "f5713036-c8f8-46c5-d25c-bc81366e12dd"
      },
      "source": [
        "img = unknown_image_batch[0]\n",
        "plt.imshow(tf.concat([img], 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb8d4288090>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRej95TYLBG8"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl23KvXmEuQP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "159376f6-9812-486e-ec82-ec3ba147ffc0"
      },
      "source": [
        "%cd /content/drive/MyDrive/onlab_results/\n",
        "wgan = WGANGP(loading=True)\n",
        "%cd /content/drive/MyDrive/onlab_results/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/onlab_results\n",
            "/content/drive/MyDrive/onlab_results/first_try\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "Model: \"generator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_63 (InputLayer)        [(None, 1, 1, 1536)]      0         \n",
            "_________________________________________________________________\n",
            "dense_80 (Dense)             (None, 1, 1, 1536)        2359296   \n",
            "_________________________________________________________________\n",
            "batch_normalization_266 (Bat (None, 1, 1, 1536)        6144      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_60 (LeakyReLU)   (None, 1, 1, 1536)        0         \n",
            "_________________________________________________________________\n",
            "reshape_35 (Reshape)         (None, 4, 4, 96)          0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_31 (UpSampling (None, 8, 8, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_159 (Conv2D)          (None, 8, 8, 48)          41472     \n",
            "_________________________________________________________________\n",
            "batch_normalization_267 (Bat (None, 8, 8, 48)          192       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_61 (LeakyReLU)   (None, 8, 8, 48)          0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_32 (UpSampling (None, 16, 16, 48)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_160 (Conv2D)          (None, 16, 16, 24)        10368     \n",
            "_________________________________________________________________\n",
            "batch_normalization_268 (Bat (None, 16, 16, 24)        96        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_62 (LeakyReLU)   (None, 16, 16, 24)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_33 (UpSampling (None, 32, 32, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_161 (Conv2D)          (None, 32, 32, 12)        2592      \n",
            "_________________________________________________________________\n",
            "batch_normalization_269 (Bat (None, 32, 32, 12)        48        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_63 (LeakyReLU)   (None, 32, 32, 12)        0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_34 (UpSampling (None, 64, 64, 12)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_162 (Conv2D)          (None, 64, 64, 6)         648       \n",
            "_________________________________________________________________\n",
            "batch_normalization_270 (Bat (None, 64, 64, 6)         24        \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_64 (LeakyReLU)   (None, 64, 64, 6)         0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_35 (UpSampling (None, 128, 128, 6)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_163 (Conv2D)          (None, 128, 128, 3)       162       \n",
            "_________________________________________________________________\n",
            "batch_normalization_271 (Bat (None, 128, 128, 3)       12        \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 128, 128, 3)       0         \n",
            "=================================================================\n",
            "Total params: 2,421,054\n",
            "Trainable params: 2,417,796\n",
            "Non-trainable params: 3,258\n",
            "_________________________________________________________________\n",
            "Model: \"discriminator\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_64 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_164 (Conv2D)          (None, 64, 64, 48)        3648      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_65 (LeakyReLU)   (None, 64, 64, 48)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_165 (Conv2D)          (None, 32, 32, 96)        115296    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_66 (LeakyReLU)   (None, 32, 32, 96)        0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 32, 32, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_166 (Conv2D)          (None, 16, 16, 192)       460992    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_67 (LeakyReLU)   (None, 16, 16, 192)       0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 16, 16, 192)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_167 (Conv2D)          (None, 8, 8, 384)         1843584   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_68 (LeakyReLU)   (None, 8, 8, 384)         0         \n",
            "_________________________________________________________________\n",
            "flatten_27 (Flatten)         (None, 24576)             0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 24576)             0         \n",
            "_________________________________________________________________\n",
            "dense_81 (Dense)             (None, 1)                 24577     \n",
            "=================================================================\n",
            "Total params: 2,448,097\n",
            "Trainable params: 2,448,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "/content/drive/MyDrive/onlab_results\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPrjZCiaEFkR"
      },
      "source": [
        "wgan.train(ds_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRH2zjBbrduh"
      },
      "source": [
        "wgan.generate_samples()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZlyQ-IzhMls"
      },
      "source": [
        "wgan.saving_models()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ3Bvm71hyB6"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grOPsY1uhxrW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fb9aa10-573e-44b8-f266-b44974c4e18d"
      },
      "source": [
        "inception_model = tf.keras.applications.InceptionV3(include_top=False, \n",
        "                              weights=\"imagenet\", \n",
        "                              pooling='avg')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131,
          "referenced_widgets": [
            "42aeaf6a24a94e48af81342f2ab79244",
            "3d9f93edc0fb41e7947aa9a4a18d426a",
            "a53da28d3412470dae10aaeb3ad422c2",
            "1fe7d547180e4146ba42782a9b68cfd1",
            "6a0c8568f99446bbaef45c20a538c012",
            "0d5a977f10244d76b9b2043573fa741d",
            "54478e910cca43eea726a69068e43fd3",
            "0bb8dc8a5d294d7fb05e53129aa7a154",
            "1377b4e3bad9423794e0957b80e0ef61",
            "6ebcc5c249d349b2a682ea9877373c2a",
            "ce6b376b1ad44d23a5325ac8ba4ea049",
            "1d3bac18c9e942a894afd06e4509513c",
            "ff4e6f0a9d664049b2717adf5a23c556",
            "0eca3e0477484ff588051c685dc82daa",
            "81a4a8ae15e348a681287992e555bb5c",
            "76ac023b1ec64c5b9c118260c344e39a"
          ]
        },
        "id": "K4ej2GTX65Z9",
        "outputId": "3b6aeabd-93a8-4319-933c-b2d953240ae0"
      },
      "source": [
        "import math\n",
        "from tqdm.autonotebook import tqdm\n",
        "import numpy as np\n",
        "def compute_embeddings(dataloader, count, generated = False):\n",
        "    image_embeddings = []\n",
        "\n",
        "    for _ in tqdm(range(count)):\n",
        "        images = next(iter(dataloader))\n",
        "        if generated:\n",
        "          z = tf.random.normal((batch, 1, 1, noise_dim))\n",
        "          images = wgan.Gen(z, training=False)\n",
        "        embeddings = inception_model.predict(images)\n",
        "\n",
        "        image_embeddings.extend(embeddings)\n",
        "\n",
        "    return np.array(image_embeddings)\n",
        "\n",
        "count = math.ceil(512/batch)\n",
        "\n",
        "# compute embeddings for real images\n",
        "real_image_embeddings = compute_embeddings(ds_train, count)\n",
        "\n",
        "# compute embeddings for generated images\n",
        "generated_image_embeddings = compute_embeddings(ds_train, count, generated = True)\n",
        "\n",
        "real_image_embeddings.shape, generated_image_embeddings.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42aeaf6a24a94e48af81342f2ab79244",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1377b4e3bad9423794e0957b80e0ef61",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((512, 2048), (512, 2048))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Q65z3127Eiw",
        "outputId": "9245d67c-156c-4ce7-af26-6acbabdb0d1d"
      },
      "source": [
        "import scipy\n",
        "def calculate_fid(real_embeddings, generated_embeddings):\n",
        "  # calculate mean and covariance statistics\n",
        "  mu1, sigma1 = real_embeddings.mean(axis=0), np.cov(real_embeddings, rowvar=False)\n",
        "  mu2, sigma2 = generated_embeddings.mean(axis=0), np.cov(generated_embeddings,  rowvar=False)\n",
        "  # calculate sum squared difference between means\n",
        "  ssdiff = np.sum((mu1 - mu2)**2.0)\n",
        "  # calculate sqrt of product between cov\n",
        "  covmean = scipy.linalg.sqrtm(sigma1.dot(sigma2))\n",
        "  # check and correct imaginary numbers from sqrt\n",
        "  if np.iscomplexobj(covmean):\n",
        "    covmean = covmean.real\n",
        "  # calculate score\n",
        "  fid = ssdiff + np.trace(sigma1 + sigma2 - 2.0 * covmean)\n",
        "  return fid\n",
        "\n",
        "fid = calculate_fid(real_image_embeddings, generated_image_embeddings)\n",
        "fid"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1618.146577655185"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoyBbxbcEhMN"
      },
      "source": [
        "# 1618.146577655185"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}